"""
Make a hdf5 file out of PIVLab txt outputs
"""


import argparse
import glob
import os
import numpy as np
from tqdm import tqdm
import h5py

def write_hdf5_dict(filepath, data_dict):
    """
    Stores data_dict
    Parameters
    ----------
    filepath :  str
                file path where data will be stored. (Do not include extension- .h5)
    data_dict : dictionary
                data should be stored as data_dict[key]= data_arrays

    Returns
    -------

    """
    filedir = os.path.split(filepath)[0]
    if not os.path.exists(filedir):
        os.makedirs(filedir)

    ext = '.h5'
    filename = filepath + ext
    hf = h5py.File(filename, 'w')
    for key in data_dict:
        hf.create_dataset(key, data=data_dict[key])
    hf.close()
    print('Data was successfully saved as ' + filename)


def pivlab2hdf5_dirbase(dirbase, scale=1., fps=1., overwrite=False):
    """
    Generate hdf5 files out of PIVLab txt outputs
    Parameters
    ----------
    dirbase

    Returns
    -------

    """
    parentdir = os.path.dirname(dirbase)
    # glob directories generated by a pivlab code
    datadirs = glob.glob(dirbase + '/*')
    for datadir in datadirs:
        output_path = parentdir + '/hdf5data/' + os.path.split(datadir)[1] + '.h5'
        if os.path.exists(output_path) and not overwrite:
            print('... %s already exists! skipping...' % (os.path.split(datadir)[1] + '.h5'))
            continue
        print('Processing %s' % datadir)

        datafiles = glob.glob(datadir + '/*.txt')
        datafiles = sorted(datafiles)

        for i, datafile in enumerate(tqdm(datafiles)):
            if not 'piv_settings/' in datafile:
                # if i % 100 == 0:
                #     print '%d / %d' % (i, len(datafiles))
                data = np.loadtxt(datafile, delimiter=',', skiprows=3)


                xx, yy = data[:, 0], data[:, 1]
                ux, uy = data[:, 2], data[:, 3]
                omega = data[:, 4]

                if i == 0:
                    delta_y = np.diff(yy)[0]
                    delta_x = delta_y

                    ncols = int((np.max(xx) - np.min(xx)) / delta_x) + 1
                    nrows = int((np.max(yy) - np.min(yy)) / delta_y) + 1
                    shape_temp = (ncols, nrows)

                    xgrid, ygrid = xx.reshape(shape_temp).T, yy.reshape(shape_temp).T

                ux_grid, uy_grid, omega_grid = ux.reshape(shape_temp).T, uy.reshape(shape_temp).T, omega.reshape(shape_temp).T

                if i == 0:
                    uxdata = np.zeros((nrows, ncols, len(datafiles)))
                    uydata = np.zeros((nrows, ncols, len(datafiles)))
                    omegadata = np.zeros((nrows, ncols, len(datafiles)))
                uxdata[..., i] = ux_grid
                uydata[..., i] = uy_grid
                omegadata[..., i] = omega_grid

        savedata = {}
        savedata['x'] = xgrid * scale
        savedata['y'] = ygrid * scale
        savedata['ux'] = uxdata * scale * fps
        savedata['uy'] = uydata * scale * fps
        savedata['omega'] = omegadata * fps

        hdf5path = parentdir + '/hdf5data/' + os.path.split(datadir)[1]
        write_hdf5_dict(hdf5path, savedata)

    print('... Done')


def pivlab2hdf5(dir, scale=1., fps=1.):
    parentdir = os.path.dirname(dir)
    # glob directories generated by a pivlab code

    print('Processing %s' % dir)

    datafiles = glob.glob(dir + '/*.txt')
    datafiles = sorted(datafiles)

    for i, datafile in enumerate(tqdm(datafiles)):
        # if i % 100 == 0:
        #     print '%d / %d' % (i, len(datafiles))
        data = np.loadtxt(datafile, delimiter=',', skiprows=3)

        xx, yy = data[:, 0], data[:, 1]
        ux, uy = data[:, 2], data[:, 3]
        omega = data[:, 4]

        if i == 0:
            delta_y = np.diff(yy)[0]
            delta_x = delta_y

            ncols = int((np.max(xx) - np.min(xx)) / delta_x) + 1
            nrows = int((np.max(yy) - np.min(yy)) / delta_y) + 1
            shape_temp = (ncols, nrows)

            xgrid, ygrid = xx.reshape(shape_temp).T, yy.reshape(shape_temp).T

        ux_grid, uy_grid, omega_grid = ux.reshape(shape_temp).T, uy.reshape(shape_temp).T, omega.reshape(
            shape_temp).T

        if i == 0:
            uxdata = np.zeros((nrows, ncols, len(datafiles)))
            uydata = np.zeros((nrows, ncols, len(datafiles)))
            omegadata = np.zeros((nrows, ncols, len(datafiles)))
        uxdata[..., i] = ux_grid
        uydata[..., i] = uy_grid
        omegadata[..., i] = omega_grid

    savedata = {}
    savedata['x'] = xgrid * scale
    savedata['y'] = ygrid * scale
    savedata['ux'] = uxdata * scale * fps
    savedata['uy'] = uydata * scale * fps
    savedata['omega'] = omegadata * fps

    hdf5path = parentdir + '/hdf5data/' + os.path.split(dir)[1]
    write_hdf5_dict(hdf5path, savedata)

    print('... Done')



def main(args):
    if args.dir is None:
        print('Make hdf5 files for directories under ' + args.dirbase)
        pivlab2hdf5_dirbase(args.dirbase, scale=args.scale, fps=args.fps)
    else:
        print('Make a hdf5 file for the following directory: ' + args.dir)
        pivlab2hdf5(args.dir, scale=args.scale, fps=args.fps)



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Make a hdf5 file out of PIVLab txt outputs')
    parser.add_argument('-dirbase', '--dirbase', help='Parent directory of PIVlab output directories', type=str,
                        default=None)
    parser.add_argument('-dir', '--dir', help='Name of a directory which contains pivlab txt outputs', type=str,
                        default=None)
    parser.add_argument('-scale', '--scale', help='Conversion factor: mm per px', type=float,
                        default=1.)
    parser.add_argument('-fps', '--fps', help='ss: frame per second', type=float,
                        default=1.)
    args = parser.parse_args()

    main(args)